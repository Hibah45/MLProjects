{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hibah45/MLProjects/blob/main/RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4Vnaz3qP5tw_"
      },
      "outputs": [],
      "source": [
        "##NLP USING RNNN\n",
        "#IMDB movie review SENTIMENTAL analysis using word of embeddings, LSTM(layer wid a loop) and dense layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mndkUoC5wZZ",
        "outputId": "a03f261c-0685-41b4-aaa9-9fef36dc27d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `2.x  # this line is not required unless you are in a notebook`. This will be interpreted as: `2.x`.\n",
            "\n",
            "\n",
            "TensorFlow 2.x selected.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n",
            "17473536/17464789 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "%tensorflow_version 2.x  # this line is not required unless you are in a notebook\n",
        "from keras.datasets import imdb\n",
        "from keras.preprocessing import sequence\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "VOCAB_SIZE = 88584\n",
        "\n",
        "MAXLEN = 250\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words = VOCAB_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSee19tG6U_o",
        "outputId": "37bb85b0-9410-43ff-b62d-ce05dee4fe70"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25000"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "len(train_data) #no of words in the training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUxNeJjD6hdf",
        "outputId": "6a537038-18aa-4c0a-8b62-c1704866bdf1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 22665, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 21631, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 31050, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32])\n",
            " list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 10156, 4, 1153, 9, 194, 775, 7, 8255, 11596, 349, 2637, 148, 605, 15358, 8003, 15, 123, 125, 68, 23141, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 36893, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 25249, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 46151, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95])\n",
            " list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5974, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 44076, 780, 8, 106, 14, 6905, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 51428, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113])\n",
            " list([1, 4, 18609, 16085, 33, 2804, 4, 2040, 432, 111, 153, 103, 4, 1494, 13, 70, 131, 67, 11, 61, 15305, 744, 35, 3715, 761, 61, 5766, 452, 9214, 4, 985, 7, 64317, 59, 166, 4, 105, 216, 1239, 41, 1797, 9, 15, 7, 35, 744, 2413, 31, 8, 4, 687, 23, 4, 33929, 7339, 6, 3693, 42, 38, 39, 121, 59, 456, 10, 10, 7, 265, 12, 575, 111, 153, 159, 59, 16, 1447, 21, 25, 586, 482, 39, 4, 96, 59, 716, 12, 4, 172, 65, 9, 579, 11, 6004, 4, 1615, 5, 23005, 7, 5168, 17, 13, 7064, 12, 19, 6, 464, 31, 314, 11, 87564, 6, 719, 605, 11, 8, 202, 27, 310, 4, 3772, 3501, 8, 2722, 58, 10, 10, 537, 2116, 180, 40, 14, 413, 173, 7, 263, 112, 37, 152, 377, 4, 537, 263, 846, 579, 178, 54, 75, 71, 476, 36, 413, 263, 2504, 182, 5, 17, 75, 2306, 922, 36, 279, 131, 2895, 17, 2867, 42, 17, 35, 921, 18435, 192, 5, 1219, 3890, 19, 20523, 217, 4122, 1710, 537, 20341, 1236, 5, 736, 10, 10, 61, 403, 9, 47289, 40, 61, 4494, 5, 27, 4494, 159, 90, 263, 2311, 4319, 309, 8, 178, 5, 82, 4319, 4, 65, 15, 9225, 145, 143, 5122, 12, 7039, 537, 746, 537, 537, 15, 7979, 4, 18665, 594, 7, 5168, 94, 9096, 3987, 15242, 11, 28280, 4, 538, 7, 1795, 246, 56615, 9, 10161, 11, 635, 14, 9, 51, 408, 12, 94, 318, 1382, 12, 47, 6, 2683, 936, 5, 6307, 10197, 19, 49, 7, 4, 1885, 13699, 1118, 25, 80, 126, 842, 10, 10, 47289, 18223, 4726, 27, 4494, 11, 1550, 3633, 159, 27, 341, 29, 2733, 19, 4185, 173, 7, 90, 16376, 8, 30, 11, 4, 1784, 86, 1117, 8, 3261, 46, 11, 25837, 21, 29, 9, 2841, 23, 4, 1010, 26747, 793, 6, 13699, 1386, 1830, 10, 10, 246, 50, 9, 6, 2750, 1944, 746, 90, 29, 16376, 8, 124, 4, 882, 4, 882, 496, 27, 33029, 2213, 537, 121, 127, 1219, 130, 5, 29, 494, 8, 124, 4, 882, 496, 4, 341, 7, 27, 846, 10, 10, 29, 9, 1906, 8, 97, 6, 236, 11120, 1311, 8, 4, 23643, 7, 31, 7, 29851, 91, 22793, 3987, 70, 4, 882, 30, 579, 42, 9, 12, 32, 11, 537, 10, 10, 11, 14, 65, 44, 537, 75, 11876, 1775, 3353, 12716, 1846, 4, 11286, 7, 154, 5, 4, 518, 53, 13243, 11286, 7, 3211, 882, 11, 399, 38, 75, 257, 3807, 19, 18223, 17, 29, 456, 4, 65, 7, 27, 205, 113, 10, 10, 33058, 4, 22793, 10359, 9, 242, 4, 91, 1202, 11377, 5, 2070, 307, 22, 7, 5168, 126, 93, 40, 18223, 13, 188, 1076, 3222, 19, 4, 13465, 7, 2348, 537, 23, 53, 537, 21, 82, 40, 18223, 13, 33195, 14, 280, 13, 219, 4, 52788, 431, 758, 859, 4, 953, 1052, 12283, 7, 5991, 5, 94, 40, 25, 238, 60, 35410, 4, 15812, 804, 27767, 7, 4, 9941, 132, 8, 67, 6, 22, 15, 9, 283, 8, 5168, 14, 31, 9, 242, 955, 48, 25, 279, 22148, 23, 12, 1685, 195, 25, 238, 60, 796, 13713, 4, 671, 7, 2804, 5, 4, 559, 154, 888, 7, 726, 50, 26, 49, 7008, 15, 566, 30, 579, 21, 64, 2574])\n",
            " list([1, 249, 1323, 7, 61, 113, 10, 10, 13, 1637, 14, 20, 56, 33, 2401, 18, 457, 88, 13, 2626, 1400, 45, 3171, 13, 70, 79, 49, 706, 919, 13, 16, 355, 340, 355, 1696, 96, 143, 4, 22, 32, 289, 7, 61, 369, 71, 2359, 5, 13, 16, 131, 2073, 249, 114, 249, 229, 249, 20, 13, 28, 126, 110, 13, 473, 8, 569, 61, 419, 56, 429, 6, 1513, 18, 35, 534, 95, 474, 570, 5, 25, 124, 138, 88, 12, 421, 1543, 52, 725, 6397, 61, 419, 11, 13, 1571, 15, 1543, 20, 11, 4, 22016, 5, 296, 12, 3524, 5, 15, 421, 128, 74, 233, 334, 207, 126, 224, 12, 562, 298, 2167, 1272, 7, 2601, 5, 516, 988, 43, 8, 79, 120, 15, 595, 13, 784, 25, 3171, 18, 165, 170, 143, 19, 14, 5, 7224, 6, 226, 251, 7, 61, 113])]\n"
          ]
        }
      ],
      "source": [
        "print(train_data[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISHAbSI46tl2",
        "outputId": "2ff4ee8e-f0b9-41bb-e6b7-f155a0f15063"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "189\n",
            "141\n"
          ]
        }
      ],
      "source": [
        "print(len(train_data[1]))\n",
        "print(len(train_data[2]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "8SRN_aI-7M3t"
      },
      "outputs": [],
      "source": [
        "#preprocessing-length of the words in each list of array is not same so either trim or add number of 0's\n",
        "train_data = sequence.pad_sequences(train_data, MAXLEN)\n",
        "test_data = sequence.pad_sequences(test_data, MAXLEN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhwtocW07yQS",
        "outputId": "fed07e2a-4c0f-49b2-d00c-fbe74517bdd4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "250\n",
            "250\n",
            "250\n",
            "250\n",
            "250\n",
            "250\n",
            "250\n",
            "250\n",
            "250\n",
            "250\n",
            "250\n",
            "250\n",
            "250\n",
            "250\n",
            "250\n"
          ]
        }
      ],
      "source": [
        "for i in range(15):\n",
        "  print(len(train_data[i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "a75Ilh-g7_UQ"
      },
      "outputs": [],
      "source": [
        "#creating a model\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(VOCAB_SIZE,32),\n",
        "    tf.keras.layers.LSTM(32),\n",
        "    tf.keras.layers.Dense(1, activation= \"sigmoid\")\n",
        "]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWGGcBIpjrMu",
        "outputId": "63883658-6ee7-408a-cf1b-24bc4eb633be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "625/625 [==============================] - 14s 14ms/step - loss: 0.4283 - accuracy: 0.8036 - val_loss: 0.3085 - val_accuracy: 0.8784\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 8s 13ms/step - loss: 0.1868 - accuracy: 0.9328 - val_loss: 0.3080 - val_accuracy: 0.8818\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 8s 13ms/step - loss: 0.0984 - accuracy: 0.9674 - val_loss: 0.3836 - val_accuracy: 0.8698\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 8s 13ms/step - loss: 0.0637 - accuracy: 0.9800 - val_loss: 0.4411 - val_accuracy: 0.8712\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 8s 13ms/step - loss: 0.0409 - accuracy: 0.9876 - val_loss: 0.5595 - val_accuracy: 0.8626\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 8s 13ms/step - loss: 0.0267 - accuracy: 0.9920 - val_loss: 0.5382 - val_accuracy: 0.8652\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 8s 13ms/step - loss: 0.0254 - accuracy: 0.9930 - val_loss: 0.5724 - val_accuracy: 0.8518\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 8s 13ms/step - loss: 0.0256 - accuracy: 0.9919 - val_loss: 0.6006 - val_accuracy: 0.8652\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 8s 13ms/step - loss: 0.0393 - accuracy: 0.9873 - val_loss: 0.7149 - val_accuracy: 0.8594\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 8s 13ms/step - loss: 0.0200 - accuracy: 0.9940 - val_loss: 0.5743 - val_accuracy: 0.8638\n"
          ]
        }
      ],
      "source": [
        "#compile and train\n",
        "\n",
        "model.compile(optimizer = 'adam', loss = 'binary_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "histoy = model.fit(train_data, train_labels,epochs =10, validation_split = 0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBBBb44Z9N-9",
        "outputId": "87485f8f-bce6-4475-e24c-0529b36187d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 5s 6ms/step - loss: 0.6614 - accuracy: 0.8424\n",
            "[0.6614065766334534, 0.8424000144004822]\n"
          ]
        }
      ],
      "source": [
        "results = model.evaluate(test_data, test_labels)\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzONQYabALoq",
        "outputId": "a021714a-85e8-4f9b-fc1c-18f8d4130017"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n",
            "1654784/1641221 [==============================] - 0s 0us/step\n",
            "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0  12  17  13  40 477  35 477]\n"
          ]
        }
      ],
      "source": [
        "word_index = imdb.get_word_index()\n",
        "\n",
        "def encode_text(text):\n",
        "  tokens = keras.preprocessing.text.text_to_word_sequence(text)\n",
        "  tokens = [word_index[word] if word in word_index else 0 for word in tokens]\n",
        "  return sequence.pad_sequences([tokens], MAXLEN)[0]\n",
        "\n",
        "text = \"that movie was just amazing, so amazing\"\n",
        "encoded = encode_text(text)\n",
        "print(encoded)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "um-bFsiiAwCL",
        "outputId": "ebf0e391-4ad1-4097-a164-5adf3e97e9ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "that movie was just amazing so amazing\n"
          ]
        }
      ],
      "source": [
        "# while were at it lets make a decode function\n",
        "\n",
        "reverse_word_index = {value: key for (key, value) in word_index.items()}\n",
        "\n",
        "def decode_integers(integers):\n",
        "    PAD = 0\n",
        "    text = \"\"\n",
        "    for num in integers:\n",
        "      if num != PAD:\n",
        "        text += reverse_word_index[num] + \" \"\n",
        "\n",
        "    return text[:-1]\n",
        "  \n",
        "print(decode_integers(encoded))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GW1-7NGFA1db",
        "outputId": "861140ed-1e09-4712-91bf-400e4e4804cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.97931015]\n",
            "[0.37021354]\n"
          ]
        }
      ],
      "source": [
        "# now time to make a prediction\n",
        "\n",
        "def predict(text):\n",
        "  encoded_text = encode_text(text)\n",
        "  pred = np.zeros((1,250))\n",
        "  pred[0] = encoded_text\n",
        "  result = model.predict(pred) \n",
        "  print(result[0])\n",
        "\n",
        "positive_review = \"That movie was wow! really loved it and would great watch it again because it was amazingly great\"\n",
        "predict(positive_review)\n",
        "\n",
        "negative_review = \"that movie really sucked. I hated it and wouldn't watch it again. Was one of the worst things I've ever watched\"\n",
        "predict(negative_review)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "rnw_fSpIA4qH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ac70c7e-8cdd-480a-a2d7-1a30b274d0f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `2.x  # this line is not required unless you are in a notebook`. This will be interpreted as: `2.x`.\n",
            "\n",
            "\n",
            "TensorFlow is already loaded. Please restart the runtime to change versions.\n"
          ]
        }
      ],
      "source": [
        "### RNN PLAY GENERATOR\n",
        "# CHARACTER DESCRIPTION -SEQUENCE\n",
        "\n",
        "%tensorflow_version 2.x  # this line is not required unless you are in a notebook\n",
        "from keras.preprocessing import sequence\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aoa5baUs3iHR",
        "outputId": "cd68879a-e611-458d-ccc6-cd1bddd35d99"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "1122304/1115394 [==============================] - 0s 0us/step\n",
            "1130496/1115394 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#loading our own file -from google.colab import files\n",
        "#path_to_file = list(files.upload().keys())[0]"
      ],
      "metadata": {
        "id": "fQLHKyZc4yqa"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "# length of text is the number of characters in it\n",
        "print ('Length of text: {} characters'.format(len(text)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElgV9r2L5HOo",
        "outputId": "2e6d1aee-bf1a-45b3-b283-4b4c422b7d76"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of text: 1115394 characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text[:50])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fw6BJH75MaS",
        "outputId": "5a39ae89-d08e-48b1-beec-2e1afc4633ce"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#convert text to int- encoding\n",
        "vocab = sorted(set(text))\n",
        "# Creating a mapping from unique characters to indices\n",
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)\n",
        "\n",
        "def text_to_int(text):\n",
        "  return np.array([char2idx[c] for c in text])\n",
        "\n",
        "text_as_int = text_to_int(text)"
      ],
      "metadata": {
        "id": "lY5o33rD5PNf"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Text:\", text[:15])\n",
        "print(\"Encoded value:\", text_to_int(text[:15]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1f_abwZ5u_3",
        "outputId": "22994433-7877-4257-f33b-7b2e00c61de3"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: First Citizen:\n",
            "\n",
            "Encoded value: [18 47 56 57 58  1 15 47 58 47 64 43 52 10  0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def int_to_text(ints):\n",
        "  try:\n",
        "    ints = ints.numpy()\n",
        "  except:\n",
        "    pass\n",
        "  return ''.join(idx2char[ints])\n",
        " \n",
        "print(int_to_text(text_as_int[:13]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1K5RF7u3505J",
        "outputId": "5caaa601-dd9f-4df0-bfcd-3558a78e05ed"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length = 100  # length of sequence for a training example\n",
        "examples_per_epoch = len(text)//(seq_length+1)\n",
        "\n",
        "# Create training examples / targets\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)"
      ],
      "metadata": {
        "id": "KylXhcew65FX"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)"
      ],
      "metadata": {
        "id": "Zq3IFST_8-l0"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_input_target(chunk):  # for the example: hello\n",
        "    input_text = chunk[:-1]  # hell\n",
        "    target_text = chunk[1:]  # ello\n",
        "    return input_text, target_text  # hell, ello\n",
        "\n",
        "dataset = sequences.map(split_input_target)  # we use map to apply the above function to every entry"
      ],
      "metadata": {
        "id": "Y52uThC99CTI"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x, y in dataset.take(1):\n",
        "  print(\"\\n\\nEXAMPLE\\n\")\n",
        "  print(\"INPUT\")\n",
        "  print(int_to_text(x))\n",
        "  print(\"\\nOUTPUT\")\n",
        "  print(int_to_text(y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kc3oyKK93A4",
        "outputId": "a7a8b649-5e3e-4238-d701-c9fda877ef4a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "EXAMPLE\n",
            "\n",
            "INPUT\n",
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You\n",
            "\n",
            "OUTPUT\n",
            "irst Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#training batches\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "VOCAB_SIZE = len(vocab)  # vocab is number of unique characters\n",
        "EMBEDDING_DIM = 256\n",
        "RNN_UNITS = 1024\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "data = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgLyu9qO-ETl",
        "outputId": "d6ce0a96-96d8-4b9f-e151-5aaa76762dd5"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<BatchDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "  model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "                              batch_input_shape=[batch_size, None]),\n",
        "    tf.keras.layers.LSTM(rnn_units,\n",
        "                        return_sequences=True,\n",
        "                        stateful=True,\n",
        "                        recurrent_initializer='glorot_uniform'),\n",
        "    tf.keras.layers.Dense(vocab_size)\n",
        "  ])\n",
        "  return model\n",
        "\n",
        "model = build_model(VOCAB_SIZE,EMBEDDING_DIM, RNN_UNITS, BATCH_SIZE)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVeP2yRL-3Gl",
        "outputId": "9ff7920f-8474-41aa-a009-6787bf083c49"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (64, None, 256)           16640     \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (64, None, 1024)          5246976   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (64, None, 65)            66625     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,330,241\n",
            "Trainable params: 5,330,241\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example_batch, target_example_batch in data.take(1):\n",
        "  example_batch_predictions = model(input_example_batch)  # ask our model for a prediction on our first batch of training data (64 entries)\n",
        "  print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")  # print out the output shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1Kzrcqk_KX6",
        "outputId": "9646b276-c1a5-44d3-9ab8-8d7f5c42d195"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 100, 65) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(example_batch_predictions))\n",
        "print(example_batch_predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8Objvp-_agX",
        "outputId": "d9228c66-7fef-4beb-fcb8-b540f2c8241e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "64\n",
            "tf.Tensor(\n",
            "[[[ 5.6881867e-03  3.6020200e-03  5.7035597e-04 ...  3.8428872e-04\n",
            "   -4.1842362e-04 -8.4423171e-03]\n",
            "  [ 5.2750963e-03  3.2986070e-03 -1.3692626e-03 ... -6.9194157e-03\n",
            "   -4.7763269e-03 -4.3482659e-03]\n",
            "  [ 1.4603925e-03  2.9668163e-03 -8.0909692e-03 ... -4.7965720e-03\n",
            "   -3.1723594e-04 -1.0739849e-03]\n",
            "  ...\n",
            "  [-5.4314621e-03  1.0296024e-02 -1.5631784e-05 ...  4.2230189e-03\n",
            "   -4.5148944e-03 -7.3566409e-03]\n",
            "  [-7.7779600e-03  8.6571770e-03 -2.6423689e-03 ... -8.3838182e-04\n",
            "   -6.4234072e-03 -6.9931289e-03]\n",
            "  [ 1.4042715e-03  1.1154210e-02 -1.9867071e-03 ... -1.0872269e-03\n",
            "   -6.5988479e-03 -1.4374333e-02]]\n",
            "\n",
            " [[ 6.4385291e-03  3.5967398e-03 -1.9490602e-03 ... -5.4593314e-04\n",
            "    3.8488302e-05 -3.0981044e-03]\n",
            "  [ 4.5345286e-03  2.0794151e-03 -2.9986058e-03 ...  1.2639884e-02\n",
            "   -3.8834296e-03 -5.8312160e-03]\n",
            "  [ 6.1514839e-03 -2.8717448e-03  2.2567483e-03 ...  1.5972415e-02\n",
            "    6.3959043e-04 -1.0162381e-02]\n",
            "  ...\n",
            "  [ 9.3829297e-03  8.0849100e-03  7.3676454e-03 ...  1.2222277e-03\n",
            "   -8.6030760e-04 -9.6541997e-03]\n",
            "  [ 5.4677227e-03  3.5872294e-03  3.6223663e-03 ...  1.4367472e-02\n",
            "   -5.0130510e-03 -9.6656587e-03]\n",
            "  [ 9.4743511e-03  5.1398473e-03  4.0783202e-03 ...  1.3846730e-02\n",
            "   -4.2950762e-03 -1.5971631e-02]]\n",
            "\n",
            " [[-6.3950010e-03 -3.2865442e-05 -8.5204962e-04 ...  3.0957987e-03\n",
            "   -3.3880004e-03 -1.4618842e-03]\n",
            "  [ 6.8817334e-04  5.2337034e-04 -2.1125195e-03 ...  5.9151831e-03\n",
            "   -2.9238409e-03 -2.2376180e-03]\n",
            "  [ 1.5318636e-03  3.0650022e-03 -2.7579810e-03 ...  3.0435589e-03\n",
            "   -6.7250603e-03  2.3610778e-03]\n",
            "  ...\n",
            "  [-2.9384403e-03 -6.3033262e-03 -7.2197625e-03 ...  5.8577908e-03\n",
            "    3.4112106e-03  5.1723756e-03]\n",
            "  [-1.8031311e-03 -2.6987125e-03  1.3259104e-03 ...  6.4242734e-03\n",
            "    3.7714969e-03  1.5215519e-03]\n",
            "  [-1.0711272e-03 -1.8750071e-03 -5.6064408e-04 ...  5.0599105e-03\n",
            "   -2.0899680e-03  4.7845943e-03]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-2.1659692e-03 -5.9863986e-03 -6.4192933e-04 ... -2.1436373e-03\n",
            "   -3.8256100e-04 -5.3922652e-04]\n",
            "  [-5.7603898e-03 -3.5532059e-03 -2.0568739e-03 ...  4.1407803e-03\n",
            "   -8.9267455e-04  5.7122926e-04]\n",
            "  [ 2.8631578e-03  7.4910565e-04 -3.1806307e-04 ...  4.8776567e-03\n",
            "   -5.8990973e-04 -7.8706387e-03]\n",
            "  ...\n",
            "  [ 4.6550804e-03 -9.5837293e-03 -9.2842020e-03 ... -9.8775802e-03\n",
            "    2.9082880e-03 -3.8294618e-03]\n",
            "  [ 5.1303185e-03 -1.4605870e-03  9.2864269e-05 ... -7.0016375e-03\n",
            "    3.9928220e-03 -4.0270383e-03]\n",
            "  [ 3.5475364e-03 -2.4275882e-03  1.4698785e-04 ... -1.2480974e-02\n",
            "    4.8531778e-04  1.4836129e-04]]\n",
            "\n",
            " [[ 4.3516802e-03  4.9336540e-04 -1.3683107e-03 ...  2.7824189e-03\n",
            "   -4.9429131e-04 -2.2334184e-03]\n",
            "  [ 9.1084940e-03  3.9352076e-03 -3.9512932e-04 ...  2.0473457e-03\n",
            "   -7.3235226e-04 -1.0327367e-02]\n",
            "  [ 7.9776254e-03  3.5490156e-03 -2.2244256e-03 ... -5.9200232e-03\n",
            "   -5.1303599e-03 -5.8491332e-03]\n",
            "  ...\n",
            "  [ 8.4745940e-03  6.3926345e-03  6.6258786e-03 ...  4.2518802e-04\n",
            "   -1.8051807e-03 -1.3988128e-02]\n",
            "  [ 6.6808113e-03  8.4413011e-03  1.0778053e-02 ... -4.0711166e-04\n",
            "   -5.1621720e-04 -1.3093958e-02]\n",
            "  [ 5.3991368e-03  7.6510552e-03  5.6954520e-03 ... -2.4599785e-03\n",
            "   -5.5417903e-03 -6.5091047e-03]]\n",
            "\n",
            " [[ 1.5592901e-05  2.8044465e-03 -1.1514866e-03 ... -1.4435304e-03\n",
            "   -4.7468529e-03  3.4075535e-03]\n",
            "  [-1.4575224e-03 -3.9193104e-03 -9.0926536e-04 ... -2.3193313e-03\n",
            "   -3.2707725e-03  1.7905806e-03]\n",
            "  [-3.8814712e-03 -1.5264463e-03  2.9734608e-03 ... -2.5756778e-03\n",
            "   -2.0193458e-03 -2.1412363e-04]\n",
            "  ...\n",
            "  [ 1.9534789e-03  4.2632814e-03  9.8154147e-04 ... -7.8310203e-03\n",
            "   -5.1413872e-03 -1.5729760e-03]\n",
            "  [ 1.9488099e-03  8.6117145e-03  8.6402930e-03 ... -4.1123391e-03\n",
            "   -2.2989125e-03 -3.4804591e-03]\n",
            "  [ 6.2821847e-03  6.8976586e-03  5.4961359e-03 ...  1.0212262e-03\n",
            "   -2.2676652e-03 -4.7327043e-03]]], shape=(64, 100, 65), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lets examine one prediction\n",
        "pred = example_batch_predictions[0]\n",
        "print(len(pred))\n",
        "print(pred)\n",
        "# notice this is a 2d array of length 100, where each interior array is the prediction for the next character at each time step"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqWmN2buAQ48",
        "outputId": "c4522393-0318-4e18-c8eb-681da6519cc8"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\n",
            "tf.Tensor(\n",
            "[[ 5.6881867e-03  3.6020200e-03  5.7035597e-04 ...  3.8428872e-04\n",
            "  -4.1842362e-04 -8.4423171e-03]\n",
            " [ 5.2750963e-03  3.2986070e-03 -1.3692626e-03 ... -6.9194157e-03\n",
            "  -4.7763269e-03 -4.3482659e-03]\n",
            " [ 1.4603925e-03  2.9668163e-03 -8.0909692e-03 ... -4.7965720e-03\n",
            "  -3.1723594e-04 -1.0739849e-03]\n",
            " ...\n",
            " [-5.4314621e-03  1.0296024e-02 -1.5631784e-05 ...  4.2230189e-03\n",
            "  -4.5148944e-03 -7.3566409e-03]\n",
            " [-7.7779600e-03  8.6571770e-03 -2.6423689e-03 ... -8.3838182e-04\n",
            "  -6.4234072e-03 -6.9931289e-03]\n",
            " [ 1.4042715e-03  1.1154210e-02 -1.9867071e-03 ... -1.0872269e-03\n",
            "  -6.5988479e-03 -1.4374333e-02]], shape=(100, 65), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prediction at the first timestep\n",
        "time_pred = pred[0]\n",
        "print(len(time_pred))\n",
        "print(time_pred)\n",
        "# and of course its 65 values representing the probabillity of each character occuring next"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xZH4BlSAcqL",
        "outputId": "1552695b-3541-481d-f36c-eea83d5b6418"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "65\n",
            "tf.Tensor(\n",
            "[ 5.6881867e-03  3.6020200e-03  5.7035597e-04  3.4793722e-03\n",
            "  2.4633864e-03  6.0740481e-03  3.1258815e-03  5.1908341e-04\n",
            "  3.9405245e-03  9.3764160e-05 -2.9805207e-03  5.2641574e-03\n",
            " -1.4060375e-04  3.8256804e-03 -4.9868515e-03 -3.1430996e-03\n",
            " -1.5701507e-03 -2.1411669e-03 -3.2229861e-03  3.4186789e-03\n",
            "  4.1990648e-03 -4.1637644e-03 -3.7829536e-03 -3.2785293e-03\n",
            "  1.2074637e-03  5.7118121e-03 -8.1768783e-04 -2.4204648e-03\n",
            " -2.2661008e-03 -5.0978512e-03 -9.2494059e-03 -2.5208844e-03\n",
            " -4.1212649e-03 -3.0847099e-03  3.6838697e-03 -1.2592531e-03\n",
            " -1.0416628e-03  4.9566338e-03 -2.9697260e-03  2.6463054e-03\n",
            " -5.0370898e-03  2.6357588e-03  1.5728405e-03  8.4599620e-04\n",
            "  2.4167839e-03  5.0809598e-03  1.2649379e-03  3.7643234e-03\n",
            "  4.8012058e-03 -2.4726107e-03  5.0231842e-03  8.8295911e-04\n",
            " -2.8861105e-06  2.2342934e-03 -1.7897999e-03 -2.1405260e-04\n",
            " -3.4906904e-03 -6.8720093e-04 -4.2959945e-03 -9.6207787e-04\n",
            "  4.9832137e-04  4.8231948e-03  3.8428872e-04 -4.1842362e-04\n",
            " -8.4423171e-03], shape=(65,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# If we want to determine the predicted character we need to sample the output distribution (pick a value based on probabillity)\n",
        "sampled_indices = tf.random.categorical(pred, num_samples=1)\n",
        "\n",
        "# now we can reshape that array and convert all the integers to numbers to see the actual characters\n",
        "sampled_indices = np.reshape(sampled_indices, (1, -1))[0]\n",
        "predicted_chars = int_to_text(sampled_indices)\n",
        "\n",
        "predicted_chars  # and this is what the model predicted for training sequence 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Cp1m2IPIAmBv",
        "outputId": "99ad22e7-9dee-42c6-aa27-68e84485b167"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"iQTe!IWxaMFkVbXFFHJ,-; LrFrye&KUP,:aJ&jQOHAWnWSdnNoWzfi$eLClI!zkADIfwn',.'Cm&JEc'vxv?JdySA.WTqjwXfz?\""
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create loss fn and compile nxt\n",
        "def loss(labels, logits):\n",
        "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)"
      ],
      "metadata": {
        "id": "YswfBoVLAz-g"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss=loss)"
      ],
      "metadata": {
        "id": "YMrGyXEhA7Gg"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ],
      "metadata": {
        "id": "sRlCOuuXBDK2"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(data, epochs=20, callbacks=[checkpoint_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_RIIeI4BLSr",
        "outputId": "05f071d4-74c8-49cc-ecd6-24332c04ed30"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "172/172 [==============================] - 13s 69ms/step - loss: 1.8844\n",
            "Epoch 2/20\n",
            "172/172 [==============================] - 13s 70ms/step - loss: 1.6387\n",
            "Epoch 3/20\n",
            "172/172 [==============================] - 13s 71ms/step - loss: 1.5062\n",
            "Epoch 4/20\n",
            "172/172 [==============================] - 13s 71ms/step - loss: 1.4249\n",
            "Epoch 5/20\n",
            "172/172 [==============================] - 13s 69ms/step - loss: 1.3696\n",
            "Epoch 6/20\n",
            "172/172 [==============================] - 13s 70ms/step - loss: 1.3238\n",
            "Epoch 7/20\n",
            "172/172 [==============================] - 13s 70ms/step - loss: 1.2865\n",
            "Epoch 8/20\n",
            "172/172 [==============================] - 14s 71ms/step - loss: 1.2498\n",
            "Epoch 9/20\n",
            "172/172 [==============================] - 13s 71ms/step - loss: 1.2162\n",
            "Epoch 10/20\n",
            "172/172 [==============================] - 13s 71ms/step - loss: 1.1814\n",
            "Epoch 11/20\n",
            "172/172 [==============================] - 13s 69ms/step - loss: 1.1461\n",
            "Epoch 12/20\n",
            "172/172 [==============================] - 13s 69ms/step - loss: 1.1110\n",
            "Epoch 13/20\n",
            "172/172 [==============================] - 13s 69ms/step - loss: 1.0737\n",
            "Epoch 14/20\n",
            "172/172 [==============================] - 13s 69ms/step - loss: 1.0358\n",
            "Epoch 15/20\n",
            "172/172 [==============================] - 13s 70ms/step - loss: 0.9950\n",
            "Epoch 16/20\n",
            "172/172 [==============================] - 13s 69ms/step - loss: 0.9563\n",
            "Epoch 17/20\n",
            "172/172 [==============================] - 13s 70ms/step - loss: 0.9158\n",
            "Epoch 18/20\n",
            "172/172 [==============================] - 13s 70ms/step - loss: 0.8769\n",
            "Epoch 19/20\n",
            "172/172 [==============================] - 13s 70ms/step - loss: 0.8388\n",
            "Epoch 20/20\n",
            "172/172 [==============================] - 13s 70ms/step - loss: 0.8021\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#load model nd check latest checkpoints\n",
        "model = build_model(VOCAB_SIZE, EMBEDDING_DIM, RNN_UNITS, batch_size=1)"
      ],
      "metadata": {
        "id": "MKnOmCPTBQIK"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "model.build(tf.TensorShape([1, None]))"
      ],
      "metadata": {
        "id": "ivwMT-mhDXGL"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model, start_string):\n",
        "  # Evaluation step (generating text using the learned model)\n",
        "\n",
        "  # Number of characters to generate\n",
        "  num_generate = 800\n",
        "\n",
        "  # Converting our start string to numbers (vectorizing)\n",
        "  input_eval = [char2idx[s] for s in start_string]\n",
        "  input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "  # Empty string to store our results\n",
        "  text_generated = []\n",
        "\n",
        "  # Low temperatures results in more predictable text.\n",
        "  # Higher temperatures results in more surprising text.\n",
        "  # Experiment to find the best setting.\n",
        "  temperature = 1.0\n",
        "\n",
        "  # Here batch size == 1\n",
        "  model.reset_states()\n",
        "  for i in range(num_generate):\n",
        "      predictions = model(input_eval)\n",
        "      # remove the batch dimension\n",
        "    \n",
        "      predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "      # using a categorical distribution to predict the character returned by the model\n",
        "      predictions = predictions / temperature\n",
        "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "\n",
        "      # We pass the predicted character as the next input to the model\n",
        "      # along with the previous hidden state\n",
        "      input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "      text_generated.append(idx2char[predicted_id])\n",
        "\n",
        "  return (start_string + ''.join(text_generated))"
      ],
      "metadata": {
        "id": "0EKl7afVDfc-"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inp = input(\"Type a starting string: \")\n",
        "print(generate_text(model, inp))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3DnzKM5EB7x",
        "outputId": "8c9c78c7-433c-427a-c308-8fa250d63721"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type a starting string: Hey Romeo. How are you\n",
            "Hey Romeo. How are you mine?\n",
            "\n",
            "HORTENSIO:\n",
            "You may made\n",
            "Falselike less repair to leave you.\n",
            "\n",
            "VINCENTIO:\n",
            "It is: my masterable death!\n",
            "\n",
            "GLOUCESTER:\n",
            "CKING HENRY VI:\n",
            "Why, what, ho! within, and humonest me where they born:\n",
            "The other, then, I doubt not\n",
            "That's laughing with execution.\n",
            "\n",
            "FLORIZEL:\n",
            "Cambon!\n",
            "\n",
            "PRINCE EDWARD:\n",
            "Come, come, we must strike, when I do confess\n",
            "To hear it good deaths.\n",
            "\n",
            "POLIXENES:\n",
            "Nou to him, and better thunder, speaking, stay.\n",
            "\n",
            "CLIFFORD:\n",
            "I will be crief from whence MIO:\n",
            "On pain of such a night issue of thy greatest not\n",
            "Count must be content to hear Cominius.\n",
            "\n",
            "DUCHESS OF YORK:\n",
            "Apollo have the little son a maidenhead, she is an honour may\n",
            "I want nor golden sort,\n",
            "Making you both:\n",
            "His unemumind hate the one declined\n",
            "A very that try, after the duke a thing\n",
            "Whereof I have thy hate than you the world\n",
            "From in\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wa1E1JzZETsS"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "RNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMSJWcdA7Mpc3Jwlu9zqxJk",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}